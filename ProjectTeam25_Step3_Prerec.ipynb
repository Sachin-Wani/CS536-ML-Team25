{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IEtmh1_VlKUV"
      },
      "source": [
        "### Import The Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B1OLcPR7mc-V"
      },
      "outputs": [],
      "source": [
        "pip install torchsummary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LxnHwXr5yRyF"
      },
      "outputs": [],
      "source": [
        "!pip install wget\n",
        "!pip install pytorch-fid\n",
        "import os\n",
        "import sys\n",
        "import wget\n",
        "import zipfile\n",
        "import time\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import imageio\n",
        "from PIL import Image\n",
        "from IPython import display\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.pyplot import imshow\n",
        "from matplotlib.image import imread\n",
        "from sklearn.metrics import accuracy_score\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision \n",
        "from torchvision import transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from tqdm.autonotebook import tqdm\n",
        "from torchsummary import summary\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
        "warnings.filterwarnings(\"ignore\", category=ImportWarning)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ChO7DxRrlPNZ"
      },
      "source": [
        "### Mount The Google Drive"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y4seI0s3lcTg"
      },
      "source": [
        "### Set the parameters like generator learning rate, Discriminator learning rate, Epochs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qeYx5EYE4l-2"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Device\n",
        "\"\"\"\n",
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "data_dir='pizza'\n",
        "\n",
        "\"\"\"\n",
        "Epochs\n",
        "\"\"\"\n",
        "epochs=40\n",
        "decay_epoch=5\n",
        "epoch_offset=1\n",
        "\"\"\"\n",
        "Size of feature maps in generator. Set the value as per DCGAN.\n",
        "\"\"\"\n",
        "ngf=64 \n",
        "\"\"\"\n",
        "Size of feature maps in discriminator.Set the value as per DCGAN.\n",
        "\"\"\" \n",
        "ndf=64\n",
        "\"\"\"\n",
        "Number of residual blocks\n",
        "\"\"\" \n",
        "num_residual_blocks=9\n",
        "\n",
        "\"\"\"\n",
        "Generator learning rate  \n",
        "\"\"\" \n",
        "lr_G=0.0002\n",
        "\"\"\"\n",
        "Discriminator learning rate\n",
        "\"\"\" \n",
        "lr_D=0.0002"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1EwIEdehlui5"
      },
      "source": [
        "### Directory Creation for storing the data "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FlQ0r2OB4zmN"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Required Functions For directory Creation\n",
        "\"\"\"\n",
        "def check_if_dir_exists(directory):\n",
        "    \"\"\"\n",
        "    Checks if 'directory' exists\n",
        "    \"\"\"\n",
        "    return(os.path.isdir(directory))\n",
        "\n",
        "def make_dir(directory):\n",
        "    \"\"\"\n",
        "    Crete directory\n",
        "    \"\"\"\n",
        "    if not check_if_dir_exists(directory):\n",
        "        os.mkdir(directory)\n",
        "        print(\"Directory %s created successfully.\" %directory)\n",
        "    else:\n",
        "        print(\"Directory %s exists.\" %directory)\n",
        "\n",
        "\"\"\"\n",
        "Required directory Creation\n",
        "\"\"\"\n",
        "cycleGAN_dir=r'C:\\Users\\idiot\\OneDrive\\Desktop\\Rutgers Materals\\CS536- ML\\Mini Project 3\\GAN'\n",
        "make_dir(cycleGAN_dir)\n",
        "\n",
        "os.chdir(r'C:\\Users\\idiot\\OneDrive\\Desktop\\Rutgers Materals\\CS536- ML\\Mini Project 3\\GAN')\n",
        "\n",
        "cycleGAN_result_dir =  'CycleGAN_Results/'\n",
        "make_dir(cycleGAN_result_dir)\n",
        "\n",
        "cycleGAN_validation_result_dir =  'CycleGAN_Validation_Results/'\n",
        "make_dir(cycleGAN_validation_result_dir)\n",
        "\n",
        "cycleGAN_test_resut_dir='CycleGAN_Test_Results/'\n",
        "make_dir(cycleGAN_test_resut_dir)\n",
        "\n",
        "cycleGAN_test_resut_x2y2x_dir='CycleGAN_Test_Results/XtoYtoX/'\n",
        "make_dir(cycleGAN_test_resut_x2y2x_dir)\n",
        "\n",
        "cycleGAN_test_resut_y2x2y_dir='CycleGAN_Test_Results/YtoXtoY/'\n",
        "make_dir(cycleGAN_test_resut_y2x2y_dir)\n",
        "\n",
        "\n",
        "cycleGAN_checkpoint_dir =  'CycleGAN_Checkpoint/'\n",
        "make_dir(cycleGAN_checkpoint_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hRd2wf-el8E-"
      },
      "source": [
        "### Extracting the data from the .zip file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cfGVZrp048iD"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Required Functions For Dataset Download and Extraction\n",
        "\"\"\"\n",
        "def check_if_file_exists(file):\n",
        "    \"\"\"\n",
        "    Checks if 'file' exists\n",
        "    \"\"\"\n",
        "    try:\n",
        "        fh = open(file, 'r')\n",
        "        return True\n",
        "    except FileNotFoundError:\n",
        "        print('Please make sure file: ' + file + ' is present before continuing')\n",
        "        return False\n",
        "\n",
        "\n",
        "# def download_dataset(data_source_url, data_file_path, data_folder_path):\n",
        "#     \"\"\"\n",
        "#     Download the Dataset\n",
        "#     \"\"\"\n",
        "#     if not check_if_file_exists(data_file_path):\n",
        "#         print('Start of data download')\n",
        "#         wget.download(url=data_source_url, out=data_folder_path)\n",
        "#         print('Download complete')\n",
        "#     else:\n",
        "#         print('Data file already exists. Not downloading again!')\n",
        "\n",
        "\n",
        "def extract_zip_file(data_folder, file_name):\n",
        "    \"\"\"\n",
        "    Extract or Unzip the downloaded the Dataset\n",
        "    \"\"\"\n",
        "    if not check_if_dir_exists(data_folder):\n",
        "        startTime = time.time()\n",
        "        with zipfile.ZipFile(file_name, 'r') as zip_file: \n",
        "            print('Extracting all the files now...') \n",
        "            zip_file.extractall() \n",
        "        print('Done!') \n",
        "        total_time=time.time()-startTime\n",
        "        print('Time Taken for extracting all files : ',total_time/60,'minutes')\n",
        "    else:\n",
        "        print('Data foler exists. Won\\'t extracting again!')\n",
        "\n",
        "# \"\"\"\n",
        "# Data source url\n",
        "# \"\"\"\n",
        "# data_source_url = 'https://drive.google.com/uc?export=download&id=1QA2dEa97Ib6mLIKi4acV6qFmS4Ig2bpK'\n",
        "# print('Data source url :',data_source_url)\n",
        "\n",
        "# \"\"\"\n",
        "# Download Dataset\n",
        "# \"\"\"\n",
        "# data_file_path=os.getcwd()+'/pizza.zip'\n",
        "# data_folder_path=os.getcwd()\n",
        "\n",
        "# download_dataset(data_source_url, data_file_path, data_folder_path)\n",
        "\n",
        "\"\"\"\n",
        "Unzip the downloaded Dataset\n",
        "\"\"\"\n",
        "data_folder=r'C:\\Users\\idiot\\OneDrive\\Desktop\\Rutgers Materals\\CS536- ML\\Mini Project 3\\GAN\\pizza'\n",
        "file_name = r'C:\\Users\\idiot\\OneDrive\\Desktop\\Rutgers Materals\\CS536- ML\\Mini Project 3\\pizza.zip'\n",
        "\n",
        "extract_zip_file(data_folder, file_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S8wSXL4omIpK"
      },
      "source": [
        "### Classify the image and save them to different folder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dSoEM7Nm5OTo"
      },
      "outputs": [],
      "source": [
        "class ImageDataset(Dataset):\n",
        "    def __init__(self, image_dir, is_train, image_type):\n",
        "        self.train_or_test='train' if is_train else 'test'\n",
        "        self.image_dir = './' + image_dir\n",
        "        self.image_type=image_type\n",
        "        self.image_path = os.path.join(self.image_dir, self.train_or_test+'{}'.format(self.image_type))\n",
        "        self.image_filename_lst = [x for x in sorted(os.listdir(self.image_path))]\n",
        "        self.transform = transform[self.train_or_test]\n",
        "        \n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        image_file = os.path.join(self.image_path, self.image_filename_lst[index])\n",
        "        image = Image.open(image_file).convert('RGB')\n",
        "        image = self.transform(image)\n",
        "        return image\n",
        " \n",
        "    def __len__(self):\n",
        "        return len(self.image_filename_lst)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cXKsYgUmmQ-Q"
      },
      "source": [
        "### Transform & Load the train and test dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TaB1VyuS7BVC"
      },
      "outputs": [],
      "source": [
        "transform = {\n",
        "             'train': transforms.Compose([transforms.Resize(size=286),\n",
        "                                          transforms.CenterCrop(256),\n",
        "                                          transforms.RandomHorizontalFlip(),\n",
        "                                          transforms.ToTensor(),\n",
        "                                          transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))]),\n",
        "             'test': transforms.Compose([transforms.Resize(size=256),\n",
        "                                         transforms.ToTensor(),\n",
        "                                         transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))])\n",
        "            }\n",
        "\"\"\"\n",
        "Train Data Loader \n",
        "\"\"\"\n",
        "train_data_X = ImageDataset(image_dir=data_dir+'/syntheticpizza/', is_train=True, image_type='A')\n",
        "                        \n",
        "train_loader_X = DataLoader(dataset=train_data_X, batch_size=1, shuffle=True)\n",
        "\n",
        "train_data_Y = ImageDataset(image_dir=data_dir+'/realpizza/', is_train=True, image_type='B')\n",
        "                        \n",
        "train_loader_Y = DataLoader(dataset=train_data_Y, batch_size=1, shuffle=True)\n",
        "\n",
        "\"\"\"\n",
        "Test Data Loader\n",
        "\"\"\"\n",
        "test_data_X = ImageDataset(image_dir=data_dir+'/syntheticpizza/', is_train=False, image_type='A')\n",
        "                        \n",
        "test_loader_X = DataLoader(dataset=test_data_X, batch_size=1, shuffle=False)\n",
        "\n",
        "test_data_Y = ImageDataset(image_dir=data_dir+'/realpizza/', is_train=False, image_type='B')\n",
        "                        \n",
        "test_loader_Y = DataLoader(dataset=test_data_Y, batch_size=1, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VgaouEVTmezA"
      },
      "source": [
        "### Plot the sample data from the original dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cou_Sjzw7ER8"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Get specific train and test images of each domain and converted to  B * C * W * H\n",
        "\"\"\"\n",
        "# H = synthetic and Z = real\n",
        "\n",
        "train_synthetic = train_data_X.__getitem__(26)\n",
        "train_real = train_data_Y.__getitem__(91)\n",
        "\n",
        "val_synthetic = test_data_X.__getitem__(78)\n",
        "val_real = test_data_Y.__getitem__(67)\n",
        "f, axarr = plt.subplots(2,1, figsize=(20,10))\n",
        "\n",
        "for i in range(2):\n",
        "        if i==0:\n",
        "            x = val_synthetic\n",
        "            s='Fake'\n",
        "        else :\n",
        "            x = val_real\n",
        "            s='Real'\n",
        "\n",
        "        grid = torchvision.utils.make_grid(x.clamp(min=-1, max=1), scale_each=True, normalize=True)\n",
        "        \"\"\"\n",
        "        Turn off axis\n",
        "        \"\"\"\n",
        "        axarr[i].set_axis_off()\n",
        "        \"\"\"\n",
        "        Plot image data\n",
        "        \"\"\"\n",
        "        axarr[i].imshow(grid.permute(1, 2, 0).cpu().numpy())\n",
        "\n",
        "        \"\"\"\n",
        "        Add the text for validation image.\n",
        "        Add the text to the axes at location coordinates.\n",
        "        \"\"\"\n",
        "        axarr[i].text(0.5, 0.05, s, dict(size=20, color='green'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PnNKEVSwm24u"
      },
      "source": [
        "### Shape before and after conversion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jyije-QS7MbA"
      },
      "outputs": [],
      "source": [
        "print('Size of val_real_Z before conversion : ',val_real.size())\n",
        "\"\"\"\n",
        "Specific train and test images of each domain  are converted to  B * C * W * H.\n",
        "\"\"\"\n",
        "print('\\nSpecific train and test images of each domain  are converted to  B * C * W * H')\n",
        "train_synthetic = torch.stack([train_synthetic])\n",
        "print('Size of train_synthetic : ',train_synthetic.size())\n",
        "train_real = torch.stack([train_real])\n",
        "print('Size of train_real : ',train_real.size())\n",
        "\n",
        "val_synthetic = torch.stack([val_synthetic])\n",
        "print('Size of val_synthetic : ',val_synthetic.size())\n",
        "val_real = torch.stack([val_real])\n",
        "print('Size of val_real : ',val_real.size())\n",
        "\n",
        "\n",
        "y=torch.squeeze(val_real).permute(1, 2, 0)\n",
        "print('\\nSize of y after torch squeeze and permute : ',y.size())\n",
        "\n",
        "\"\"\"\n",
        "Getting Image shape which will be passed to summary function to get modules output saphe and parameter summary\n",
        "\"\"\"\n",
        "z=torch.squeeze(val_real)\n",
        "print('\\nPreparing the image shape that will be used in summary function later : ',z.size())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "STLC-W_bm93g"
      },
      "source": [
        "### Plot sample images of real and fake data after transformation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AOY-VFns7RBa"
      },
      "outputs": [],
      "source": [
        "def set_seed(seed):\n",
        "    torch.manual_seed(seed)\n",
        "    np.random.seed(seed)\n",
        "\n",
        "set_seed(42)\n",
        "\n",
        "img_idx_lst=np.random.randint(0,1000,8)\n",
        "\n",
        "def show_images(data_X, data_Y):\n",
        "    rows, cols,=2, 4\n",
        "    f, axarr = plt.subplots(rows,cols, figsize=(20,10))\n",
        "\n",
        "    for i in range(rows):\n",
        "        for j in range(cols):\n",
        "            if i==0:\n",
        "                x = data_X.__getitem__(img_idx_lst[i*4+j])\n",
        "                s='Fake'\n",
        "            else :\n",
        "                x = data_Y.__getitem__(img_idx_lst[i*4+j])\n",
        "                s='Real'\n",
        "\n",
        "            grid = torchvision.utils.make_grid(x.clamp(min=-1, max=1), scale_each=True, normalize=True)\n",
        "            \"\"\"\n",
        "            Turn off axis\n",
        "            \"\"\"\n",
        "            axarr[i,j].set_axis_off()\n",
        "            \"\"\"\n",
        "            Plot image data\n",
        "            \"\"\"\n",
        "            axarr[i,j].imshow(grid.permute(1, 2, 0).cpu().numpy())\n",
        "\n",
        "            \"\"\"\n",
        "            Add the text for validation image.\n",
        "            Add the text to the axes at location coordinates.\n",
        "            \"\"\"\n",
        "            axarr[i,j].text(0.5, 0.05, s, dict(size=20, color='blue'))\n",
        "    \n",
        "\n",
        "show_images(train_data_X, train_data_Y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yeXq8yD57Y5n"
      },
      "outputs": [],
      "source": [
        "def to_numpy_and_scale(x):\n",
        "   \"\"\"\n",
        "   Function to prepare the image tensor to work with matplotlib \n",
        "   \"\"\"\n",
        "   grid = torchvision.utils.make_grid(x.clamp(min=-1, max=1), scale_each=True, normalize=True)\n",
        "   \n",
        "   return grid.permute(1, 2, 0).detach().cpu().numpy()\n",
        "   \n",
        "\n",
        "def generate_result(real_image, gen_image, recon_image, epoch, result_dir, is_test=False, show=False):\n",
        "    \"\"\"\n",
        "    Create and conditinaly show real image with fake and reconstructed images generated by generators.\n",
        "    This function is used to generate both train and test result based on parameters.\n",
        "    \"\"\"\n",
        "    titles = ['Original(synthetic)', 'Generated(Real)', 'Reconstructed(synthetic)']\n",
        "    if is_test:\n",
        "        images=[to_numpy_and_scale(real_image[0]),  to_numpy_and_scale(gen_image[0]), to_numpy_and_scale(recon_image[0])]\n",
        "        fig, axarr = plt.subplots(1, 3, figsize=(10,10))\n",
        "    else:\n",
        "        images = [to_numpy_and_scale(real_image[0]), to_numpy_and_scale(gen_image[0]), to_numpy_and_scale(recon_image[0]),\n",
        "                  to_numpy_and_scale(real_image[1]), to_numpy_and_scale(gen_image[1]), to_numpy_and_scale(recon_image[1])]\n",
        "                    \n",
        "        fig, axarr = plt.subplots(2, 3, figsize=(10,10))\n",
        "\n",
        "    for i in range(len(images)):\n",
        "        if not is_test:\n",
        "            if i < 3:\n",
        "                nrows=0\n",
        "                ncols=i\n",
        "                \n",
        "                title_i=i\n",
        "            else:\n",
        "                nrows=1\n",
        "                ncols=i - 3\n",
        "                title_i=i-3\n",
        "            ax=axarr[nrows][ncols]\n",
        "        else:\n",
        "            title_i=i\n",
        "            ax=axarr[i]\n",
        "            \n",
        "  \n",
        "        \"\"\"\n",
        "        Turn off axis of the plot\n",
        "        \"\"\"\n",
        "        ax.set_axis_off()\n",
        "        \"\"\"\n",
        "        Plot image data\n",
        "        \"\"\"\n",
        "        \n",
        "        ax.imshow(images[i], aspect='equal')\n",
        "        \"\"\"\n",
        "        Set Title of individual subplot\n",
        "        \"\"\"\n",
        "        ax.set_title(titles[title_i], color='red', fontsize = 16)\n",
        "    \"\"\"\n",
        "    Tune the subplot layout\n",
        "    \"\"\"\n",
        "    plt.subplots_adjust(wspace=0, hspace=0)\n",
        "\n",
        "    if not is_test:\n",
        "        \"\"\"\n",
        "        Add the text for train and validation image.\n",
        "        Add the text to the axes at location coordinates.\n",
        "        \"\"\"\n",
        "        fig.text(0.5, 0.05, 'Epoch {}'.format(epoch + 1), horizontalalignment='center', fontsize=16, color='red')\n",
        "\n",
        "    \"\"\"\n",
        "    Save every plot.\n",
        "    \"\"\"\n",
        "    if not is_test:\n",
        "        result_file = os.path.join(result_dir,'CycleGAN_Result_Epoch_{}'.format(epoch+1) + '.png')\n",
        "    else:    \n",
        "        result_file = os.path.join(result_dir + 'CycleGAN_Test_Result_{}'.format(epoch + 1) + '.png')\n",
        "\n",
        "    plt.savefig(result_file)\n",
        "\n",
        "    \"\"\"\n",
        "    Display(Conditional)\n",
        "    \"\"\"\n",
        "    if show and is_test:\n",
        "         plt.show()\n",
        "    else:\n",
        "        plt.close()\n",
        "\n",
        "\n",
        "def real_gen_recon_image(G_1,G_2,real_image):\n",
        "    \"\"\"\n",
        "    This function is used to generate fake and reconstructed images generated by generators\n",
        "    \"\"\"\n",
        "    \"\"\"\n",
        "    Move image to the device.\n",
        "    \"\"\"\n",
        "    real_image = real_image.to(device)\n",
        "\n",
        "    \"\"\"\n",
        "    Real To Genereted To Reconstruction\n",
        "    \"\"\"\n",
        "    fake_image = G_1(real_image)\n",
        "    reconstructed_image = G_2(fake_image)\n",
        "\n",
        "    return fake_image,reconstructed_image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3SU4ozUA7cRR"
      },
      "outputs": [],
      "source": [
        "def update_image_buffer_and_get_image(image_buffer, input_images, capacity):\n",
        "\n",
        "    if capacity == 0:\n",
        "        return input_images\n",
        "\n",
        "    return_images = []\n",
        "\n",
        "    for input_image in input_images.data:\n",
        "        input_image = torch.stack([input_image])\n",
        "        \"\"\"\n",
        "        Populate the image buffer one by one until its reaches the capacity.\n",
        "        \"\"\"\n",
        "        if len(image_buffer) < capacity:\n",
        "            image_buffer.append(input_image)\n",
        "            return_images.append(input_image)\n",
        "\n",
        "        elif random.random() > 0.5:\n",
        "            \"\"\"\n",
        "            Probabilistically, replace an existing fake image and use replaced fake image.\n",
        "            \"\"\"\n",
        "            randId = random.randint(0, capacity-1)\n",
        "            return_images.append(image_buffer[randId])\n",
        "            image_buffer[randId] = input_image\n",
        "        else:\n",
        "            \"\"\"\n",
        "            Probabilistically, uses a generated fake image directly.\n",
        "            \"\"\"\n",
        "            return_images.append(input_image)\n",
        "            \n",
        "    return_images = torch.cat(return_images, 0)\n",
        "  \n",
        "    return return_images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rIoqLJS-q4l6"
      },
      "source": [
        "### Different type of Activation Function "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MKBrLD_99hdN"
      },
      "outputs": [],
      "source": [
        "def activation_func(activation_name):\n",
        "    return  nn.ModuleDict([\n",
        "        ['relu', nn.ReLU(inplace=True)],\n",
        "        ['leaky', nn.LeakyReLU(0.2, inplace=True)],\n",
        "        ['tanh', nn.Tanh()],\n",
        "        ['none', nn.Identity()]\n",
        "    ])[activation_name]\n",
        "\n",
        "pad_func=lambda kernel_size: (kernel_size-1)//2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4yVqPaSKrBz9"
      },
      "source": [
        "### Reflection Padding is added for Convolution\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YAhelUKv7lTY"
      },
      "outputs": [],
      "source": [
        "class Conv(nn.Module):\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, kernel_size=3, stride=2, padded=False, activation='relu', norm=True):\n",
        "        super().__init__()\n",
        "\n",
        "        kernel = (kernel_size,kernel_size)\n",
        "        \"\"\"\n",
        "        if Reflection pad is used, set padding param to 0 as already padded \n",
        "        \"\"\"\n",
        "        padding = pad_func(kernel_size) if not padded else 0 \n",
        "\n",
        "        self.conv = nn.Conv2d(in_channels,out_channels,kernel,stride,padding)\n",
        "        self.norm = norm\n",
        "        self.ins = nn.InstanceNorm2d(out_channels)\n",
        "        self.activation = activation_func(activation)\n",
        "        \n",
        "\n",
        "    def forward(self,x):\n",
        "\n",
        "        if self.norm:\n",
        "            x = self.ins(self.conv(x))\n",
        "        else:\n",
        "            x = self.conv(x)\n",
        "\n",
        "        return self.activation(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GrsyIHDwrh5O"
      },
      "source": [
        "### Deconvolution Layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k4arJaSg7n8U"
      },
      "outputs": [],
      "source": [
        "class Deconv(nn.Module):\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, kernel_size=3, stride=2):\n",
        "        super().__init__()\n",
        "\n",
        "        pad = pad_func(kernel_size)\n",
        "        out_pad=pad\n",
        "        kernel = (kernel_size,kernel_size)\n",
        "\n",
        "        self.deconv = nn.ConvTranspose2d(in_channels,out_channels,kernel,stride,pad,out_pad)\n",
        "        self.ins = nn.InstanceNorm2d(out_channels)\n",
        "        self.relu = activation_func('relu')\n",
        "\n",
        "    def forward(self,x):\n",
        "            x = self.relu(self.ins(self.deconv(x)))\n",
        "            return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7A1oCXslrq1Q"
      },
      "source": [
        "### Residual Block Body with strides "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YjH0dimh7ujX"
      },
      "outputs": [],
      "source": [
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, channels, kernel_size=3, stride=1):\n",
        "        super().__init__()\n",
        "        \"\"\"\n",
        "        Input and channel remain same (i.e. 256 ==> R256 as per paper.)\n",
        "        Keeping stride = 1 to maintain the shape.This two also eleminate Shortcut part to make 1x1 convolution as a \"projection\". \n",
        "        \"\"\"\n",
        "        \"\"\"\n",
        "        128*64*64 To 128*66*66\n",
        "        \"\"\"\n",
        "        pad=pad_func(kernel_size)\n",
        "        self.reflection_pad = nn.ReflectionPad2d(pad)\n",
        "        \"\"\"\n",
        "        128*64*64 To 128*64*64  \n",
        "        then reflection_pad so 128*64*64 To 128*66*66\n",
        "        \"\"\"\n",
        "        self.conv1 = Conv(channels,channels,kernel_size,stride=stride,padded=True)\n",
        "        \"\"\"\n",
        "        128*66*66 To 128*64*64\n",
        "        \"\"\"\n",
        "        self.conv2 = Conv(channels,channels,kernel_size,stride=stride,padded=True,activation='none')\n",
        "      \n",
        "        self.relu1 = activation_func('relu')\n",
        "\n",
        "        \"\"\"\n",
        "        Shortcut part is the identify function, which returns the input as the output\n",
        "        Unless the output of will have a different shape due to a change in\n",
        "        the number of channels or stride, then we will make the short cut\n",
        "        a 1x1 convolution as a \"projection\" to change it's shape.\n",
        "         \n",
        "        Which in this case will never execute as channels are same and stride=1. Hence skiping that part.\n",
        "        \"\"\" \n",
        "          \n",
        "\n",
        "    def forward(self,x):\n",
        "        \"\"\"\n",
        "        Compute the results of F_x and x, as needed \n",
        "        \"\"\"\n",
        "        residual=x\n",
        "        f_x = self.conv1(self.reflection_pad(x))\n",
        "        f_x = self.conv2(self.reflection_pad(f_x))\n",
        "        x = self.relu1(residual + f_x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y9IbdouKrcry"
      },
      "source": [
        "### Components of Generator Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SITFiSbV8BMw"
      },
      "outputs": [],
      "source": [
        "class Generator(nn.Module):\n",
        "    def __init__(self, in_channels, n_filter, out_channels, n_residual_blocks,kernel_size=7):\n",
        "        super().__init__()\n",
        "        \"\"\"\n",
        "        Component of generator : \n",
        "            * Initial Convolution Block\n",
        "            * Encoder\n",
        "            * Residual blocks\n",
        "            * Decoder\n",
        "            * Output Convolution Block\n",
        "\n",
        "        kernel_size=7 for two conv layers : Initial Convolution Block and Output Convolution Block.\n",
        "        But rest conv layers of encoder and residual block or deconv layers of decoder have 3 as kernal size which is by defalut initialzed\n",
        "        by the Conv and Deconv class.\n",
        "        \"\"\"\n",
        "\n",
        "        \"\"\"\n",
        "        Initial Convolution Block\n",
        "        Reflection padding ==> 3*256*256 To 3*262*262\n",
        "        c7s1-64 ==>#3*262*262 To 64*256*256\n",
        "\n",
        "        Generator input size is  3 * 256 * 256\n",
        "        As per paper, this initial conv layer will have kernel size=7 so inorder to keep the image size (W,H) same \n",
        "        we need to pad it by padding of size (kernel_size-1)//2 =7-1//2 = 3\n",
        "        As per paper I use Reflection padding to reduce artifact.\n",
        "        \"\"\"\n",
        "        pad = pad_func(kernel_size)\n",
        "        generator = nn.ModuleList([nn.ReflectionPad2d(pad), #3*256*256 To 3*262*262\n",
        "                     Conv(in_channels,n_filter,kernel_size=kernel_size,stride=1,padded=True) #3*262*262 To 64*256*256\n",
        "                    ])\n",
        "      \n",
        "        \"\"\"\n",
        "        Encoder\n",
        "        Downsampling\n",
        "        d128 ==> 64*256*256 To 128*128*128\n",
        "        d256 ==> 128*128*128 To 256*64*64\n",
        "        \"\"\"\n",
        "        generator += nn.ModuleList([Conv(n_filter,n_filter*2), #64*256*256 To 128*128*128\n",
        "                      Conv(n_filter*2,n_filter*4)#128*128*128 To 256*64*64\n",
        "                     ])\n",
        "\n",
        "        \"\"\"\n",
        "        Residual blocks : R256,R256,R256,R256,R256,R256,R256,R256,R256\n",
        "        ==> 256*64*64 To 256*64*64\n",
        "        \"\"\"\n",
        "      \n",
        "        generator +=nn.ModuleList([ResidualBlock(n_filter*4) for i in range(n_residual_blocks)])#256*64*64 To 256*64*64\n",
        "        \n",
        "        \"\"\"\n",
        "        Decoder\n",
        "        Upsampling\n",
        "        u128 ==> 256*64*64 To 128*128*128\n",
        "        u64 ==> #128*128*128 To 64*256*256 \n",
        "        \"\"\"\n",
        "        generator += nn.ModuleList([Deconv(n_filter*4,n_filter*2),#256*64*64 To 128*128*128\n",
        "                      Deconv(n_filter*2,n_filter)#128*128*128 To 64*256*256 Then reflection_pad so 64*256*256 To 64*262*262\n",
        "                     ])\n",
        "        \n",
        "        \"\"\"\n",
        "        Output Layer\n",
        "        Then reflection_pad so 64*256*256 To 64*262*262\n",
        "        c7s1-3 ==> 64*262*262 To 3*256*256 \n",
        "\n",
        "        The previous decoder gives image outcome of size 64*256*256.\n",
        "        Discriminator takes image of size 3*256*256\n",
        "        As per paper, this output conv layer will have kernel size=7 \n",
        "        so inorder to keep the image size (W,H) same \n",
        "        need to pad it by padding of size (kernel_size-1)//2 =7-1//2 = 3\n",
        "        As per paper I use Reflection padding to reduce artifact.\n",
        "        \"\"\"\n",
        "        generator += nn.ModuleList([nn.ReflectionPad2d(pad),\n",
        "                      Conv(n_filter,out_channels,kernel_size=kernel_size,stride=1,padded=True,activation='tanh',norm=False)#64*262*262 To 3*256*256\n",
        "                     ])\n",
        "        \n",
        "        self.generator = nn.Sequential(*generator)\n",
        "\n",
        "    def forward(self,x):\n",
        "        return self.generator(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TFpE_JmIszi8"
      },
      "source": [
        "### Discriminator Architechture 70 ×70 PatchGAN with k=4 filters and stride 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J6zSipMc8Ec3"
      },
      "outputs": [],
      "source": [
        "def f(output_size, ksize, stride):\n",
        "    return (output_size - 1) * stride + ksize\n",
        "last_layer = f(output_size=1, ksize=4, stride=1)\n",
        "\"\"\"Receptive field: 4\"\"\"\n",
        "fourth_layer = f(output_size=last_layer, ksize=4, stride=1)\n",
        "\"\"\"Receptive field: 7\"\"\"\n",
        "third_layer = f(output_size=fourth_layer, ksize=4, stride=2)\n",
        "\"\"\"Receptive field: 16\"\"\"\n",
        "second_layer = f(output_size=third_layer, ksize=4, stride=2)\n",
        "\"\"\"Receptive field: 34\"\"\"\n",
        "first_layer = f(output_size=second_layer, ksize=4, stride=2)\n",
        "\"\"\"Receptive field: 70\"\"\"\n",
        "print(first_layer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UbI7DWd9tKyh"
      },
      "source": [
        "### Discriminitor Architechture C64 −C128 −C256 −C512 with leaky ReLU."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bABiOev48Klh"
      },
      "outputs": [],
      "source": [
        "class Discriminator(nn.Module):\n",
        "    def __init__(self,in_channels,n_filter,out_channels,kernel_size=4):\n",
        "        super().__init__()\n",
        "        \"\"\"\n",
        "        C64\n",
        "        3*256*256 To 64*128*128\n",
        "        \"\"\"\n",
        "        discriminator = nn.ModuleList([Conv(in_channels,n_filter,kernel_size=kernel_size,stride=2,activation='leaky',norm=False)])\n",
        "        \"\"\"\n",
        "        C128\n",
        "        64*128*128 To 128*64*64\n",
        "        \"\"\"\n",
        "        discriminator += nn.ModuleList([Conv(n_filter,n_filter*2,kernel_size=kernel_size,stride=2,activation='leaky')])\n",
        "        \"\"\"\n",
        "        C256\n",
        "        128*64*64 To 256*32*32\n",
        "        \"\"\"\n",
        "        discriminator += nn.ModuleList([Conv(n_filter*2,n_filter*4,kernel_size=kernel_size,stride=2,activation='leaky')])\n",
        "        \"\"\"\n",
        "        C512\n",
        "        256*32*32 To  512*31*31\n",
        "        \"\"\"\n",
        "        discriminator += nn.ModuleList([Conv(n_filter*4,n_filter*8,kernel_size=kernel_size,stride=1,activation='leaky')])\n",
        "        \"\"\"\n",
        "        Final layer, so no need of normalization and activation.\n",
        "        512*31*31 To  1*30*30\n",
        "        \"\"\"\n",
        "        discriminator += nn.ModuleList([Conv(n_filter*8,out_channels,kernel_size=kernel_size,stride=1,activation='none',norm=False)])\n",
        "\n",
        "        \n",
        "        self.discriminator =nn.Sequential(*discriminator)\n",
        "      \n",
        "    def forward(self,x):\n",
        "        x = self.discriminator(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jT3YrAu08YHV"
      },
      "source": [
        "### Weight initialization from a Gaussian distribution N (0, 0.02)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V_N6mnVT8Rnb"
      },
      "outputs": [],
      "source": [
        "def weights_init(m):\n",
        "    for layer in m.children():\n",
        "        if isinstance(layer, nn.Conv2d) or isinstance(layer, nn.ConvTranspose2d):\n",
        "            nn.init.normal_(layer.weight, mean=0.0, std=0.02)\n",
        "            if layer.bias is not None:\n",
        "                nn.init.zeros_(layer.bias)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZJ_OJc5r8gLs"
      },
      "source": [
        "### Creation of Generators and Discriminators"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IQeuVCbP8iox"
      },
      "outputs": [],
      "source": [
        "def create_cyclegan_model(n_gen_filter, n_dcrmnt_filter, n_residual_blocks, load_state=False):\n",
        "    \"\"\"\n",
        "    * Creates 2 Generators and 2 Discriminators.\n",
        "    * In case of restoring the states of original models this function will only create 2 Generators.\n",
        "    * Place the created models on the correct compute resource (CPU or GPU).\n",
        "    * Models' weight initialized from a Gaussian distribution N (0, 0.02) except for restoring the states of original models.\n",
        "    \"\"\"\n",
        "    \n",
        "    \"\"\"\n",
        "    Create Generators\n",
        "    \"\"\"\n",
        "    G_XtoY = Generator(in_channels=3, n_filter=n_gen_filter, out_channels=3, n_residual_blocks=n_residual_blocks)\n",
        "    G_YtoX = Generator(in_channels=3, n_filter=n_gen_filter, out_channels=3, n_residual_blocks=n_residual_blocks)\n",
        "\n",
        "    \"\"\"\n",
        "    Place the models on the correct compute resource (CPU or GPU)\n",
        "    \"\"\"\n",
        "    G_XtoY.to(device)\n",
        "    G_YtoX.to(device)\n",
        "\n",
        "    print('Created Generators and move them to the correct compute resource (CPU or GPU)')\n",
        "   \n",
        "    \"\"\"\n",
        "    Create Discriminators and Place the models on the correct compute resource (CPU or GPU).\n",
        "    Models' weight initialized from a Gaussian distribution N (0, 0.02)\n",
        "    \"\"\"\n",
        "    if not load_state:\n",
        "        G_XtoY.apply(weights_init)\n",
        "        G_YtoX.apply(weights_init)\n",
        "\n",
        "        print('Generators\\' weight initialized from a Gaussian distribution N (0, 0.02)')\n",
        "\n",
        "        D_X = Discriminator(in_channels=3,n_filter=n_dcrmnt_filter,out_channels=1)\n",
        "        D_Y = Discriminator(in_channels=3,n_filter=n_dcrmnt_filter,out_channels=1)\n",
        "\n",
        "        D_X.to(device)\n",
        "        D_Y.to(device)\n",
        "        \n",
        "        print('Created Discriminators and move them to the correct compute resource (CPU or GPU)')\n",
        "        \n",
        "        D_X.apply(weights_init)\n",
        "        D_Y.apply(weights_init)\n",
        "\n",
        "        print('Discriminators\\' weight initialized from a Gaussian distribution N (0, 0.02)')\n",
        "\n",
        "\n",
        "    if not load_state:\n",
        "        return G_XtoY, G_YtoX, D_X, D_Y\n",
        "    else:\n",
        "        return G_XtoY, G_YtoX"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ulbE_eM18sMS"
      },
      "outputs": [],
      "source": [
        "G_XtoY, G_YtoX, D_X, D_Y = create_cyclegan_model(n_gen_filter=ngf, n_dcrmnt_filter=ndf, n_residual_blocks=num_residual_blocks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JFyp2X7u9DLe"
      },
      "outputs": [],
      "source": [
        "def show_cyclegan_architechture(model_dict):\n",
        "    \"\"\"\n",
        "    Show cycleGAN's generators and discriminators architechture.\n",
        "    \"\"\"\n",
        "    print(\"*\"*100)\n",
        "    print(\"CycleGAN's Generators And Discriminators Architechture\".rjust(75)) \n",
        "    print(\"*\"*100 + \"\\n\\n\")\n",
        "\n",
        "    for m in model_dict:\n",
        "        print(\"*\"*100)\n",
        "        print(m.rjust(50))\n",
        "        print(\"*\"*100)\n",
        "        print(model_dict[m])\n",
        "        print(\"*\"*100)\n",
        "        print('\\n\\n')\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "Show the structure of all of the models of CycleGAN\n",
        "\"\"\"\n",
        "show_cyclegan_architechture({'G_XtoY':G_XtoY,\n",
        "                             'G_YtoX':G_YtoX,\n",
        "                             'D_X':D_X,\n",
        "                             'D_Y':D_Y})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KPi75eCA-QBv"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "The AdamW optimizer is a good default optimizer.\n",
        "As per Equation 3 of paper(Equivalent Equation I, the code representation)\n",
        "generators' losses and cycle losses are combined for bakpropagation and \n",
        "update state(theta) which indicate to have \n",
        "one optimizer for total generator loss with parameter from both generators. \n",
        "\"\"\"      \n",
        "generators_parameters = list(G_XtoY.parameters()) + list(G_YtoX.parameters())\n",
        "optimizer_G = torch.optim.AdamW(generators_parameters,  lr=lr_G, betas=(0.5, 0.999))\n",
        "optimizer_D_X = torch.optim.AdamW(D_X.parameters(), lr=lr_D, betas=(0.5, 0.999))\n",
        "optimizer_D_Y = torch.optim.AdamW(D_Y.parameters(), lr=lr_D, betas=(0.5, 0.999))\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "Loss Functions\n",
        "\"\"\"\n",
        "mse_criterion = nn.MSELoss()\n",
        "l1_criterion = nn.L1Loss()\n",
        "\n",
        "\"\"\"\n",
        "Establish convention for real and fake labels during training\n",
        "\"\"\"\n",
        "real_label = 1.0\n",
        "fake_label = 0.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "9ITJm7O2-UF6",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "to_track =[\"Epochs\", \"Total_time\", \"D_X_losses\", \"D_Y_losses\", \"G_XtoY_losses\", \"G_YtoX_losses\", \"cycle_X_losses\", \"cycle_Y_losses\"]\n",
        "\"\"\"\n",
        "How long have we spent in the training loop?   \n",
        "\"\"\"\n",
        "total_train_time = 0     \n",
        "results = {}\n",
        "\n",
        "\"\"\"\n",
        "Initialize every item with an empty list.\n",
        "\"\"\"\n",
        "for item in to_track:\n",
        "    results[item] = []\n",
        "\n",
        "\"\"\"\n",
        "Learning rate update schedulers.\n",
        "Adjust Learing rate : Linear decay of learning rate to zero after 100 epochs.\n",
        "\"\"\"\n",
        "lambda_lr_func = lambda epoch: 1.0 - max(0, epoch + epoch_offset - decay_epoch) / (epochs - decay_epoch)\n",
        "\n",
        "lr_scheduler_G   = torch.optim.lr_scheduler.LambdaLR(optimizer_G, lr_lambda = lambda_lr_func)\n",
        "lr_scheduler_D_X = torch.optim.lr_scheduler.LambdaLR(optimizer_D_X, lr_lambda = lambda_lr_func)\n",
        "lr_scheduler_D_Y = torch.optim.lr_scheduler.LambdaLR(optimizer_D_Y, lr_lambda = lambda_lr_func)\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "Creating image buffer of capacity 50 to hold Generated image as per the paper.\n",
        "\"\"\"\n",
        "buffer_capacity = 50\n",
        "\n",
        "fake_X_buffer = []\n",
        "fake_Y_buffer = []\n",
        "\n",
        "\n",
        "for epoch in tqdm(range(epochs), desc=\"Epochs\", disable=False):\n",
        "    \"\"\"\n",
        "    Put models in training mode.\n",
        "    \"\"\"\n",
        "    G_XtoY = G_XtoY.train()\n",
        "    G_YtoX = G_YtoX.train()\n",
        "    D_X = D_X.train()\n",
        "    D_Y = D_Y.train()\n",
        "\n",
        "    G_XtoY_running_loss = 0.0\n",
        "    G_YtoX_running_loss = 0.0\n",
        "    D_X_running_loss = 0.0\n",
        "    D_Y_running_loss = 0.0\n",
        "    cycle_X_running_loss= 0.0\n",
        "    cycle_Y_running_loss= 0.0\n",
        "    \n",
        "    \n",
        "    \n",
        "    start = time.time()\n",
        "    for real_X, real_Y in tqdm(zip(train_loader_X, train_loader_Y), desc=\"Train Batch\", leave=False, disable=False):\n",
        "        \n",
        "        \"\"\"\n",
        "        Move the batch to the device we are using. \n",
        "        \"\"\"\n",
        "        real_X = real_X.to(device)\n",
        "        real_Y = real_Y.to(device)\n",
        "        \n",
        "        \"\"\"\n",
        "        ****************************** Train Generators *******************************\n",
        "        \n",
        "        ***************************** Train Generator G_XtoY **************************\n",
        "        \"\"\"\n",
        "\n",
        "        \"\"\"\n",
        "        Generator: G_XtoY: real_X -> Fake_Y \n",
        "        Forward Pass Through Generator : First, generate fake_Y fake images and reconstruct reconstructed_X images.\n",
        "        \"\"\"\n",
        "        \"\"\"\n",
        "        PyTorch stores gradients in a mutable data structure. So we need to set it to a clean state before we use it. \n",
        "        Otherwise, it will have old information from a previous iteration.\n",
        "        \"\"\"\n",
        "        optimizer_G.zero_grad()\n",
        "        \"\"\"\n",
        "        1. G_XtoY Generator generates fake_Y fake images that look like domain Y based on real real_X images of domain X.\n",
        "        \"\"\"\n",
        "        fake_Y = G_XtoY(real_X)\n",
        "        \"\"\"\n",
        "        2. Compute the generator loss based on the response of D_Y.\n",
        "        \"\"\"\n",
        "        D_Y_fake_out = D_Y(fake_Y)#1*1*30*30\n",
        "        G_XtoY_loss = mse_criterion(D_Y_fake_out, torch.full(D_Y_fake_out.size(), real_label, device=device))\n",
        "        \"\"\"\n",
        "        3. G_YtoX Generator generates reconstructed reconstructed_X images based on the fake_Y fake images generated in step 1.\n",
        "        \"\"\"\n",
        "        reconstructed_X = G_YtoX(fake_Y)\n",
        "        \"\"\"\n",
        "        Forward Cycle Consistency Loss\n",
        "        Forward cycle loss:  lambda * ||G_YtoX(G_XtoY(X)) - X|| (Equation 2 in the paper)\n",
        "        4. Compute the cycle consistency loss by comparing the reconstructed reconstructed_X images with real real_X  images of domain X.\n",
        "           Lambda for cycle loss is 10.0. Penalizing 10 times and forcing to learn the translation. \n",
        "        \"\"\"\n",
        "        cycle_X_loss = l1_criterion(reconstructed_X, real_X) * 10.0\n",
        "        \n",
        "        \"\"\"\n",
        "        ***************************** Train Generator G_YtoX **************************\n",
        "        Generator: G_YtoX: real_Y -> Fake_X\n",
        "        Backward Pass Through Generator : Now, generate fake_X fake images and reconstruct reconstructed_Y images.\n",
        "        \"\"\"\n",
        "        \"\"\"\n",
        "        5. G_YtoX Generator generates fake_X fake images that look like domain X based on real real_Y images of domain Y.\n",
        "        \"\"\"\n",
        "        fake_X = G_YtoX(real_Y)\n",
        "        \"\"\"\n",
        "        6. Compute the generator loss based on the respondse of D_X.\n",
        "        \"\"\"\n",
        "        D_X_fake_out= D_X(fake_X)\n",
        "        G_YtoX_loss = mse_criterion(D_X_fake_out, torch.full(D_X_fake_out.size(), real_label, device=device))\n",
        "        \"\"\"\n",
        "        7. G_XtoY Generator generates reconstructed reconstructed_Y images based on the fake_X fake images generated in step 5.\n",
        "        \"\"\"\n",
        "        reconstructed_Y = G_XtoY(fake_X)\n",
        "        \"\"\"\n",
        "        Backward Cycle Consistency Loss\n",
        "        Backward cycle loss: lambda * ||G_XtoY(G_YtoX(Y)) - Y|| (Equation 2)\n",
        "        8. Compute the cycle consistency loss by comparing the reconstructed reconstructed_Y images with real real_Y images of domain Y.\n",
        "           Lambda for cycle loss is 10.0. Penalizing 10 times and forcing to learn the translation.\n",
        "        \"\"\"\n",
        "        cycle_Y_loss = l1_criterion(reconstructed_Y, real_Y) * 10.0\n",
        "        \n",
        "        \"\"\"\n",
        "        Finally, Total Generators Loss and Back propagation\n",
        "        9. Add up all the Generators loss and cyclic loss (Equation 3 of paper.also Equation I the code representation of the equation) and perform backpropagation with optimization.\n",
        "        \"\"\"\n",
        "        G_loss = G_XtoY_loss + G_YtoX_loss + cycle_X_loss + cycle_Y_loss\n",
        "        \"\"\"\n",
        "        ∇_Θ just got computed by this one call!\n",
        "        \"\"\"\n",
        "        G_loss.backward()\n",
        "        \"\"\"\n",
        "        Now we just need to update all the parameters! \n",
        "        Θ_{k+1} = Θ_k − η * ∇_Θ ℓ(y_hat, y)\n",
        "        \"\"\"\n",
        "        optimizer_G.step()\n",
        "        \n",
        "        G_XtoY_running_loss+=G_XtoY_loss.item()\n",
        "        G_YtoX_running_loss+=G_YtoX_loss.item()\n",
        "        \n",
        "        cycle_X_running_loss+=cycle_X_loss.item()\n",
        "        cycle_Y_running_loss+=cycle_Y_loss.item()\n",
        "        \n",
        "        \"\"\"\n",
        "        ***************************** Train Discriminators ****************************\n",
        "\n",
        "        *************************** Train Discriminator D_X ***************************\n",
        "        Discriminator: D_X: G_YtoX(Y) vs. X \n",
        "        First, real and fake loss of Discriminator D_X .\n",
        "        \"\"\"\n",
        "        \"\"\"\n",
        "        PyTorch stores gradients in a mutable data structure. So we need to set it to a clean state before we use it. \n",
        "        Otherwise, it will have old information from a previous iteration.\n",
        "        \"\"\"\n",
        "        optimizer_D_X.zero_grad()\n",
        "        \"\"\"\n",
        "        Train D_X with real real_X images of domain X.\n",
        "        1. Compute D_X_real_loss, the real loss of discriminator D_X on real real_X images of domain X.\n",
        "        \"\"\"\n",
        "        D_X_real_out = D_X(real_X)\n",
        "        D_X_real_loss = mse_criterion(D_X_real_out, torch.full(D_X_real_out.size(), real_label, device=device))\n",
        "        \"\"\"\n",
        "        Train with fake_X fake image(History of generated images stored in the image buffer).\n",
        "        2. Get generated fake_X fake image from Image Buffer that look like domain X and based on real images in domain Y.\n",
        "        \"\"\"\n",
        "        fake_X = update_image_buffer_and_get_image(fake_X_buffer,fake_X,buffer_capacity)\n",
        "        \"\"\"\n",
        "        3. Compute D_X_fake_loss, the fake loss for discriminator D_X on fake images generated by generator.\n",
        "        \"\"\"\n",
        "        D_X_fake_out = D_X(fake_X)\n",
        "        D_X_fake_loss = mse_criterion(D_X_fake_out, torch.full(D_X_fake_out.size(), fake_label, device=device))\n",
        "        \"\"\"\n",
        "        Back propagation\n",
        "        As per the paper, I multiplied the loss for the discriminator by 0.5 during training, \n",
        "        in order to slow down updates to the discriminator relative to the generator model during training.\n",
        "        4. Compute the total loss for D_X, perform backpropagation and D_X optimization.(equation II)\n",
        "        \"\"\"\n",
        "        D_X_loss = (D_X_real_loss + D_X_fake_loss) * 0.5\n",
        "        \"\"\"\n",
        "        ∇_Θ just got computed by this one call!\n",
        "        \"\"\"\n",
        "        D_X_loss.backward()\n",
        "        \"\"\"\n",
        "        Now we just need to update all the parameters! \n",
        "        Θ_{k+1} = Θ_k − η * ∇_Θ ℓ(y_hat, y)\n",
        "        \"\"\"\n",
        "        optimizer_D_X.step()\n",
        "\n",
        "        D_X_running_loss+=D_X_loss.item()\n",
        "        \"\"\"\n",
        "        *************************** Train Discriminator D_Y ***************************\n",
        "        Discriminator: D_Y: G_XtoY(X) vs. Y.\n",
        "        Now, real and fake loss of Discriminator D_Y.\n",
        "        \"\"\"\n",
        "        \"\"\"\n",
        "        PyTorch stores gradients in a mutable data structure. So we need to set it to a clean state before we use it. \n",
        "        Otherwise, it will have old information from a previous iteration.\n",
        "        \"\"\"\n",
        "        optimizer_D_Y.zero_grad()\n",
        "        \"\"\"\n",
        "        Train D_Y with real real_Y images.\n",
        "        5. Compute D_Y_real_loss, the real loss of discriminator D_Y on real real_Y images.\n",
        "        \"\"\"\n",
        "        D_Y_real_out = D_Y(real_Y)\n",
        "        D_Y_real_loss = mse_criterion(D_Y_real_out, torch.full(D_Y_real_out.size(), real_label, device=device))\n",
        "        \"\"\"\n",
        "        Train with fake fake_Y images(History of generated images stored in the image buffer).\n",
        "        6. Get generated fake_Y fake images from Image Buffer that look like domain Y and based on real images in domain X.\n",
        "        \"\"\"\n",
        "        fake_Y = update_image_buffer_and_get_image(fake_Y_buffer,fake_Y,buffer_capacity)\n",
        "        \"\"\"\n",
        "        7. Compute D_Y_fake_loss,the fake loss for discriminator D_Y on fake images.\n",
        "        \"\"\"\n",
        "        D_Y_fake_out = D_Y(fake_Y)\n",
        "        D_Y_fake_loss = mse_criterion(D_Y_fake_out, torch.full(D_Y_fake_out.size(), fake_label, device=device))\n",
        "        \n",
        "        \"\"\"\n",
        "        Back propagation\n",
        "        As per the paper, I multiplied the loss for the discriminator by 0.5 during training, \n",
        "        in order to slow down updates to the discriminator relative to the generator model during training.\n",
        "        8. Compute the total loss for D_Y, perform backpropagation and D_Y optimization.(Equation III)\n",
        "        \"\"\"\n",
        "        D_Y_loss = (D_Y_real_loss + D_Y_fake_loss) * 0.5\n",
        "        \"\"\"\n",
        "        ∇_Θ just got computed by this one call!\n",
        "        \"\"\"\n",
        "        D_Y_loss.backward()\n",
        "        \"\"\"\n",
        "        Now we just need to update all the parameters! \n",
        "        Θ_{k+1} = Θ_k − η * ∇_Θ ℓ(y_hat, y)\n",
        "        \"\"\"\n",
        "        optimizer_D_Y.step()\n",
        "\n",
        "        D_Y_running_loss+=D_Y_loss.item()\n",
        "    \n",
        "    \"\"\"\n",
        "    End training epoch.\n",
        "    \"\"\"\n",
        "    end = time.time()\n",
        "    total_train_time += (end-start)\n",
        "    \n",
        "\n",
        "    \"\"\"\n",
        "    Values for plot.\n",
        "    \"\"\"\n",
        "    results[\"Epochs\"].append(epoch)\n",
        "    results[\"Total_time\"].append(total_train_time)\n",
        "    results[\"D_X_losses\"].append(D_X_running_loss)\n",
        "    results[\"D_Y_losses\"].append(D_Y_running_loss)\n",
        "    results[\"G_XtoY_losses\"].append(G_XtoY_running_loss)\n",
        "    results[\"G_YtoX_losses\"].append(G_YtoX_running_loss)\n",
        "    results[\"cycle_X_losses\"].append(cycle_X_running_loss)\n",
        "    results[\"cycle_Y_losses\"].append(cycle_Y_running_loss)\n",
        "    \n",
        "    \"\"\"\n",
        "    Generating result for a specific train image of each domain to see the progress in fake image generation.\n",
        "    \"\"\"\n",
        "    train_fake_Z, train_reconstructed_H = real_gen_recon_image(G_XtoY,G_YtoX,train_synthetic)\n",
        "    train_fake_H, train_reconstructed_Z = real_gen_recon_image(G_YtoX,G_XtoY,train_real)\n",
        "\n",
        "\n",
        "    generate_result([train_synthetic, train_real], \n",
        "                    [train_fake_Z, train_fake_H], \n",
        "                    [train_reconstructed_H, train_reconstructed_Z],\n",
        "                    epoch,  \n",
        "                    result_dir=cycleGAN_result_dir)\n",
        "    \"\"\"\n",
        "    Generating result for a specific valiadtion image of each domain to see the progress in fake image generation.\n",
        "    \"\"\"\n",
        "    if val_synthetic is None or val_real is None :\n",
        "        pass\n",
        "    else:\n",
        "        G_XtoY = G_XtoY.eval()\n",
        "        G_YtoX = G_YtoX.eval()\n",
        "        \n",
        "        val_fake_real, val_reconstructed_synthetic = real_gen_recon_image(G_XtoY,G_YtoX,val_synthetic)\n",
        "        val_fake_synthetic, val_reconstructed_real = real_gen_recon_image(G_YtoX,G_XtoY,val_real)\n",
        "\n",
        "\n",
        "        generate_result([val_synthetic, val_real], \n",
        "                        [val_fake_real, val_fake_synthetic], \n",
        "                        [val_reconstructed_synthetic, val_reconstructed_real],\n",
        "                        epoch, \n",
        "                        result_dir=cycleGAN_validation_result_dir)\n",
        "    \n",
        "    \"\"\"\n",
        "    In PyTorch, the convention is to update the learning rate after every epoch.\n",
        "    Updating learning rates.\n",
        "    \"\"\"\n",
        "    lr_scheduler_G.step()\n",
        "    lr_scheduler_D_X.step()\n",
        "    lr_scheduler_D_Y.step()\n",
        "    \n",
        "    \"\"\"\n",
        "    Showing lr deacy for few epochs.For 0 to 99 epoch lr is .0002.\n",
        "    For the next\n",
        "    Change in value for all optimizers' lr  are same hence showong only one lr.\n",
        "    \"\"\"\n",
        "    if (epoch+1) in [99,100,120,180,199]:\n",
        "        lr = optimizer_G.param_groups[0]['lr']\n",
        "        print('optimizer_G\\'s learning rate = %.7f' % lr,' at epoch : ', epoch)\n",
        "\n",
        "    \"\"\"\n",
        "    Save the models checkpoint.\n",
        "    \"\"\" \n",
        "    torch.save({'epoch'                   : epoch,\n",
        "                'G_XtoY_state_dict'       : G_XtoY.state_dict(),\n",
        "                'G_YtoX_state_dict'       : G_YtoX.state_dict(),\n",
        "                'D_X_state_dict'          : D_X.state_dict(),\n",
        "                'D_Y_state_dict'          : D_Y.state_dict(),\n",
        "                'optimizer_G_state_dict'  : optimizer_G.state_dict(),\n",
        "                'optimizer_D_X_state_dict': optimizer_D_X.state_dict(),\n",
        "                'optimizer_D_Y_state_dict': optimizer_D_Y.state_dict(),\n",
        "                'results'                 : results\n",
        "                }, cycleGAN_checkpoint_dir + 'CycleGAN.pt')\n",
        "    \n",
        "\"\"\"\n",
        "Creating DataFrame to hold losses which will be used to generate plot.\n",
        "\"\"\"\n",
        "results_df =  pd.DataFrame.from_dict(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TZtc7sAvmc-l"
      },
      "outputs": [],
      "source": [
        "checkpoint_dict = torch.load(cycleGAN_checkpoint_dir + 'CycleGAN.pt')\n",
        "loaded_results_df =  pd.DataFrame.from_dict(checkpoint_dict['results'])\n",
        "\n",
        "plt.figure(figsize=(10,5))\n",
        "plt.title(\"Generators and Discriminators Losses and Cyclic Losses During CycleGAN Training\", fontsize=16)\n",
        "plt.xlabel('Number of Epochs', fontsize=14)\n",
        "plt.ylabel('Train Losses', fontsize=14)\n",
        "\n",
        "for col in loaded_results_df.columns[2:]:\n",
        "    plt.plot(loaded_results_df[col], label=col)\n",
        "\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pQEnedRsBI3F"
      },
      "source": [
        "### Evaluation of Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lcmv7WblBCbc"
      },
      "outputs": [],
      "source": [
        "G_XtoY, G_YtoX = create_cyclegan_model(n_gen_filter=ngf, n_dcrmnt_filter=ndf, n_residual_blocks=num_residual_blocks, \n",
        "                                       load_state=True)\n",
        "G_XtoY.load_state_dict(checkpoint_dict['G_XtoY_state_dict'])\n",
        "\n",
        "G_YtoX.load_state_dict(checkpoint_dict['G_YtoX_state_dict'])\n",
        "\n",
        "G_XtoY = G_XtoY.eval()\n",
        "G_YtoX = G_YtoX.eval()\n",
        "\"\"\"\n",
        "Test Result Generation and Selective result show\n",
        "\"\"\"\n",
        "\n",
        "print('Synthetic ----------------> Real ----------------> Synthetic\\n\\n')\n",
        "for i, real_X in enumerate(tqdm(test_loader_X, desc=\"Test Batch X To Y To X\", leave=False, disable=False)):\n",
        "    \"\"\"\n",
        "    X To Y To X\n",
        "    \"\"\"\n",
        "    fake_Y, reconstructed_X = real_gen_recon_image(G_XtoY, G_YtoX, real_X)\n",
        "  \n",
        "    \"\"\"\n",
        "    Generating result for all test data of domain X\n",
        "    Showing only few results\n",
        "    \"\"\"\n",
        "    show=False\n",
        "    if i in [2,8,11,49,78,88,101,111]:\n",
        "        show=True\n",
        "\n",
        "    generate_result([real_X], [fake_Y], [reconstructed_X], i, result_dir=cycleGAN_test_resut_x2y2x_dir, is_test=True, show=show)\n",
        "\n",
        "print('\\n%d test images (X To Y To X) are generated.\\n\\n' % (i + 1))\n",
        "\n",
        "print('Real ----------------> Synthetic ----------------> Real\\n\\n')\n",
        "for i, real_Y in enumerate(tqdm(test_loader_Y, desc=\"Test Batch Y To X To Y\", leave=False, disable=False)):\n",
        "    \"\"\"\n",
        "    Y To X To Y\n",
        "    \"\"\"\n",
        "    fake_X, reconstructed_Y = real_gen_recon_image(G_YtoX, G_XtoY, real_Y)\n",
        "\n",
        "    \"\"\"\n",
        "    Generating result for all test data  of domain Y\n",
        "    Showing only few results\n",
        "    \"\"\"\n",
        "    show=False\n",
        "    if i in [27,28,58,67,91,93]:\n",
        "        show=True\n",
        "        \n",
        "    generate_result([real_Y], [fake_X], [reconstructed_Y], i, result_dir=cycleGAN_test_resut_y2x2y_dir, is_test=True, show=show)\n",
        "\n",
        "print('\\n%d test images (Y To X To Y) are generated.' % (i + 1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B3zHM2RhcZAi"
      },
      "source": [
        "## Step 2: Quantitative evaluation of GANs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QBRlyqducYYZ"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "FID Score: Referred from https://github.com/mseitzer/pytorch-fid\n",
        "and Reconstruction error from https://www.sciencedirect.com/science/article/abs/pii/S1077314218304272\n",
        "\"\"\"\n",
        "#FID SCORE USING DATASETS OF REAL IMAGES AND RECONSTRUCTED IMAGES (Synthetic)\n",
        "!python -m pytorch_fid MPDL/pizza/syntheticpizza/testA MPDL/CycleGAN_Test_Results/XtoYtoX\n",
        "\n",
        "#FID SCORE USING DATASETS OF REAL IMAGES AND RECONSTRUCTED IMAGES (Real)\n",
        "!python -m pytorch_fid MPDL/pizza/realpizza/testB MPDL/CycleGAN_Test_Results/YtoXtoY\n",
        "\n",
        "total_loss_X = []\n",
        "print('Synthetic ----------------> Real ----------------> Synthetic\\n\\n')\n",
        "for i, real_X in enumerate(tqdm(test_loader_X, desc=\"Test Batch X To Y To X\", leave=False, disable=False)):\n",
        "    \"\"\"\n",
        "    X To Y To X\n",
        "    \"\"\"\n",
        "    fake_Y, reconstructed_X = real_gen_recon_image(G_XtoY, G_YtoX, real_X)\n",
        "    #Reconstruction error between real_X and reconstrcuted_X\n",
        "    l1 = nn.L1Loss(reduction='sum')\n",
        "    total_loss_X.append(l1(reconstructed_X, real_X))\n",
        "\n",
        "ER_X = np.sum(total_loss_X)/len(total_loss_X)\n",
        "print(\"Reconstruction Loss for Synthetic Pizza: %.7f\" %ER_X)\n",
        "\n",
        "\n",
        "total_loss_Y = []\n",
        "print('Real ----------------> Synthetic ----------------> Real\\n\\n')\n",
        "for i, real_Y in enumerate(tqdm(test_loader_Y, desc=\"Test Batch Y To X To Y\", leave=False, disable=False)):\n",
        "    \"\"\"\n",
        "    Y To X To Y\n",
        "    \"\"\"\n",
        "    fake_X, reconstructed_Y = real_gen_recon_image(G_YtoX, G_XtoY, real_Y)\n",
        "    #Reconstruction error between real_Y and reconstrcuted_Y\n",
        "    l1 = nn.L1Loss(reduction='sum')\n",
        "    total_loss_Y.append(l1(reconstructed_Y, real_Y))\n",
        "\n",
        "ER_Y = np.sum(total_loss_Y)/len(total_loss_Y)\n",
        "print(\"Reconstruction Loss for Real Pizza: %.7f\" %ER_Y)\n",
        "\n",
        "\n",
        "## KID score calculated using KID score from file as shown in the report"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -nc https://raw.githubusercontent.com/brpy/colab-pdf/master/colab_pdf.py\n",
        "from colab_pdf import colab_pdf\n",
        "colab_pdf('ProjectTeam25_CycleGAN_Step1.ipynb')"
      ],
      "metadata": {
        "id": "ykavu1V3nh4s"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "ProjectTeam25-Step2-Prerec.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}